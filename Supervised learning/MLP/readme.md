
##  Multi Layer Preceptron

A multi-layer perceptron (MLP) has the same structure of a single layer perceptron with one or more hidden layers. The backpropagation algorithm consists of two phases: the forward phase where the activations are propagated from the input to the output layer, and the backward phase, where the error between the observed actual and the requested nominal value in the output layer is propagated backwards in order to modify the weights and bias values.
##  Dataset Used
Data from MNIST (hand written data).
##  Task
To build hidden layers and train  and compile the weights of the given datasets.
Testing our trainned model with some external jpg image to compare the accuracy of our model.
##  Libraries Used

Pandas https://pandas.pydata.org/

Matplotlib https://matplotlib.org/

Numpy https://numpy.org/

Seaborn https://seaborn.pydata.org/

Scikit-learn https://scikit-learn.org/